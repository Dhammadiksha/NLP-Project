{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1149166-e064-45a9-86c7-fc2abd287319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sample:\n",
      "                  id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n",
      "\n",
      "Dataset Info:\n",
      " None\n",
      "\n",
      "Missing Values:\n",
      " id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "toxic_target     0\n",
      "dtype: int64\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     28671\n",
      "           1       0.92      0.61      0.73      3244\n",
      "\n",
      "    accuracy                           0.95     31915\n",
      "   macro avg       0.94      0.80      0.85     31915\n",
      "weighted avg       0.95      0.95      0.95     31915\n",
      "\n",
      "Accuracy Score: 0.9548488171706094\n",
      "\n",
      "Custom Predictions:\n",
      "Comment: You are a horrible person! | Prediction: Toxic\n",
      "Comment: I really enjoyed working with you. | Prediction: Non-Toxic\n",
      "Comment: What an idiot. | Prediction: Toxic\n",
      "Comment: Have a great day! | Prediction: Non-Toxic\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Display dataset info\n",
    "print(\"Dataset Sample:\\n\", df.head())\n",
    "print(\"\\nDataset Info:\\n\", df.info())\n",
    "\n",
    "# Combine toxic categories into a single target column\n",
    "df['toxic_target'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)\n",
    "df['toxic_target'] = df['toxic_target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# check for missing values\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Fill missing comments with an empty string\n",
    "df['comment_text'] = df['comment_text'].fillna(\"\")\n",
    "\n",
    "# Data preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() # Convert to lowercase\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text) # Remove punctuation\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    text = re.sub(r'\\s', ' ', text)\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['comment_text'].apply(preprocess_text)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X = df['cleaned_text']\n",
    "y = df['toxic_target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Build the classification model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Testing the model with custom input\n",
    "def predict_toxicity(comment):\n",
    "    processed_comment = preprocess_text(comment)\n",
    "    tfidf_comment = vectorizer.transform([processed_comment])\n",
    "    prediction = model.predict(tfidf_comment)\n",
    "    return \"Toxic\" if prediction[0] == 1 else \"Non-Toxic\"\n",
    "\n",
    "# Test cases\n",
    "test_comments = [\n",
    "    \"You are a horrible person!\",\n",
    "    \"I really enjoyed working with you.\",\n",
    "    \"What an idiot.\",\n",
    "    \"Have a great day!\"\n",
    "]\n",
    "\n",
    "print(\"\\nCustom Predictions:\")\n",
    "for comment in test_comments:\n",
    "    print(f\"Comment: {comment} | Prediction: {predict_toxicity(comment)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f209ea9-0484-4f3a-b482-2a30558e6033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
